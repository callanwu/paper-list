- Hallucination
  - [Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models](https://arxiv.org/pdf/2309.01219.pdf)
  - [LLM Lies: Hallucinations are not Bugs, but Features as Adversarial Examples](https://arxiv.org/pdf/2310.01469.pdf)

- Retrieval-Augmented Generation
  - [Benchmarking Large Language Models in Retrieval-Augmented Generation](https://arxiv.org/pdf/2309.01431.pdf)
  - [Query Rewriting for Retrieval-Augmented Large Language Models](https://arxiv.org/pdf/2305.14283.pdf)
  - [LLM Self-Reflective Retrieval-Augmented Generation](https://arxiv.org/pdf/2310.11511.pdf)
  - [Learning to Filter Context for Retrieval-Augmented Generation](https://arxiv.org/pdf/2311.08377.pdf)
  - [PEARL: Personalizing Large Language Model Writing Assistants with Generation-Calibrated Retrievers](https://arxiv.org/pdf/2311.09180.pdf)

- Parameter-Efficient Fine-Tuning
  - [LLaMA-Adapter: Efficient Fine-tuning of Language Models with Zero-init Attention](https://arxiv.org/pdf/2303.16199.pdf)
  - [LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models](https://browse.arxiv.org/pdf/2309.12307.pdf)
  - [LLM-Adapters: An Adapter Family for Parameter-Efficient Fine-Tuning of Large Language Models](https://arxiv.org/pdf/2304.01933.pdf)
  - [Towards a Unified View of Parameter-Efficient Transfer Learning](https://arxiv.org/pdf/2110.04366.pdf)
  - [LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models](https://arxiv.org/pdf/2310.08659.pdf)
  - [Scaling Relationship on Learning Mathematical Reasoning with Large Language Models](https://arxiv.org/pdf/2308.01825.pdf)
  - [LoRAMoE: Revolutionizing Mixture of Experts for Maintaining World Knowledge in Language Model Alignment](https://arxiv.org/abs/2312.09979)
  - [LoraRetriever: Input-Aware LoRA Retrieval and Composition for Mixed Tasks in the Wild](https://arxiv.org/pdf/2402.09997.pdf)
  - [DeMuX: Data-efficient Multilingual Learning](https://arxiv.org/pdf/2311.06379.pdf)
    
- Attack
  - [Universal and Transferable Adversarial Attacks on Aligned Language Models](https://arxiv.org/pdf/2307.15043.pdf)
  - [AutoDAN: Generating Stealthy Jailbreak Prompts on Aligned Large Language Models](https://arxiv.org/pdf/2310.04451.pdf)
  - [Catastrophic (ðŸ˜”) Jailbreak of Open-source LLMs via Exploiting Generation](https://arxiv.org/pdf/2310.06987.pdf)
  - [LLM Lies: Hallucinations are not Bugs, but Features as Adversarial Examples](https://arxiv.org/pdf/2310.01469.pdf)
  - [Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!](https://arxiv.org/pdf/2310.03693.pdf)
  - [Language Model Inversion](https://openreview.net/pdf?id=t9dWHpGkPj)

- Model Editing
  - [Editing Large Language Models: Problems, Methods, and Opportunities](https://arxiv.org/pdf/2305.13172.pdf)
  - [Can We Edit Multimodal Large Language Models?](https://arxiv.org/pdf/2310.08475.pdf)
  - [Locating and Editing Factual Associations in GPT](https://arxiv.org/pdf/2202.05262.pdf)
  - [Emptying the Ocean with a Spoon: Should We Edit Models?](https://arxiv.org/pdf/2310.11958.pdf)
  
- Causal Inference
  - [Psychologically-Inspired Causal Prompts](https://arxiv.org/pdf/2305.01764.pdf)
  - [Causal Intervention and Counterfactual Reasoning for Multi-modal Fake News Detection](https://aclanthology.org/2023.acl-long.37.pdf)
  - [Contextual Debiasing for Visual Recognition with Causal Mechanisms](https://openaccess.thecvf.com/content/CVPR2022/papers/Liu_Contextual_Debiasing_for_Visual_Recognition_With_Causal_Mechanisms_CVPR_2022_paper.pdf)
  
- Constrained Generation
  - [Autoregressive Entity Retrieval](https://arxiv.org/pdf/2010.00904.pdf)
  - [COLD Decoding: Energy-based Constrained Text Generation with Langevin Dynamics](https://arxiv.org/pdf/2202.11705.pdf)
  - [TEXT2EVENT: Controllable Sequence-to-Structure Generation for End-to-end Event Extraction](https://arxiv.org/pdf/2106.09232.pdf)
  - [Improving Open-Ended Text Generation via Adaptive Decoding](https://arxiv.org/pdf/2402.18223.pdf)

- Agent
  - [Agent-FLAN: Designing Data and Methods of Effective Agent Tuning for Large Language Models](https://arxiv.org/pdf/2403.12881.pdf)

- Regulation
  - [LLM can Achieve Self-Regulation via Hyperparameter Aware Generation](https://arxiv.org/pdf/2402.11251.pdf)
  
- Fun
  - [Pretraining on the Test Set Is All You Need](https://arxiv.org/pdf/2309.08632.pdf)
